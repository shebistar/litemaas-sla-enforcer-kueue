<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Lab Guide: Exploring Agentic AI using LlamaStack :: Platform Foundation Bootcamp - RHOAI</title>
    <link rel="canonical" href="https://redhat-ai-services.github.io/rhoai-platform-foundation-bootcamp-instructions/modules/97_agentic_ai_llama_stack_introduction.html">
    <meta name="generator" content="Antora 3.1.14">
<link rel="stylesheet" href="../_/css/site.css"><link rel="stylesheet" href="../_/css/site-extra.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<meta name="robots" content="all">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://demo.redhat.com/images/favicon.ico" type="image/x-icon">
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar"  style="background-color: #131313 !important;">
    <div class="navbar-brand">
      <div style="display: flex; flex-direction:row; padding: 12px 32px; gap: 16px;">
     </div>
      <div class="navbar-item site-title" style="color: #fff !important;flex: 1;">Platform Foundation Bootcamp - RHOAI</div>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="modules" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title" style="display: none;"><a href="index.html" class=" query-params-link">Navigation</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="01_welcome.html">Welcome and Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="05_environment_provisioning.html">Environment Provisioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">AI-Accelerator</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="20_ai-accelerator_review.html">Project Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="07_installation.html">Bootstrap Installation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="30_gitops_env_setup_dev_prod.html">Setup Dev &amp; Prod Environments</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">RHOAI Administration</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="32_dashboard_configuration.html">RHOAI Dashboard Configuration</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Notebooks</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="31_custom_notebook.html">Custom Notebook</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="09_remote_connect_notebook.html">Connect to Workbench Kernel</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Train, Store (S3), Deploy</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="33_model_training_car.html">Model Training</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="34_using_s3_storage.html">Using S3 Storage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="36_deploy_model.html">Deploy Model</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Data Science Pipelines</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="40_setup_pipeline_server.html">Setup Pipeline Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="41_introduction_to_kfp_pipelines.html">KFP Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="kfp_elyra_differences.html">Comparison between Elyra and KFP</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="build_custom_runtime_image.html">Custom Runtime Image</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="introduction_to_elyra_pipelines.html">Elyra Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="42_working_with_pipelines.html">Working with Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="43_custom_runtime_image.html">Advanced Pipeline Customization</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Distributed Training</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="50_distributed_training.html">Ray Cluster</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Large Language Model [LLM]</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="60_llm_explore.html">Explore LLMs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="70_rag_llm.html">RAG with LLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="composer_ai.html">Composer AI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Monitoring Data Science Models</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="80_trustyai_overview.html">TrustyAI Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="81_llm_evaluation.html">Evaluating Large Language Models</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Disconnected Environment</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="disconnected_install.html">RHOAI on Disconnected Environment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">GPU as a Service</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="90_environment_provisioning.html">Provisioning a GPU Environment with NVIDIA A10G Tensor Core GPU</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="91_gpu_as_a_service_intro.html">Introduction: GPU as a Service with GPU slicing and Kueue</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="92_nvidia_gpu_operator.html">Configuring NVIDIA GPU Time-Slicing on OpenShift</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="93_kueue_setup.html">Red Hat build of Kueue Operator Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="94_kueue_gpu_pricing_tier.html">Implementing GPU Pricing Tiers with Kueue</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="95_kueue_fair_sharing.html">Advanced GPU Quota Management and Preemption with Kueue</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Model-as-a-Service</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="100_maas_intro.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="101_maas_bootstrap.html">Environment Bootstrap</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="102_maas_as_developer.html">Using MaaS as Developer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="103_maas_as_platform_engineer.html">Configure a new model</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="104_maas_monitor.html">Monitor usage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Agentic AI with Llama Stack</span>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="97_agentic_ai_llama_stack_introduction.html">Introduction &amp; Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="98_agentic_ai_llama_stack_notebook_agents.html">Agentic AI Agents with Llama Stack Clients</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="99_agentic_ai_llama_stack_playground.html">Llama Stack Playground</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="#99_useful_tips.adoc">Useful Tips</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="#97_syncing_fork.adoc">Syncing Forked Project</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Navigation</span>
      <ul class="versions">
        <li class="version is-current">
          <a href="index.html">default</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="01_welcome.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li>Agentic AI with Llama Stack</li>
    <li><a href="97_agentic_ai_llama_stack_introduction.html">Introduction &amp; Setup</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<article class="doc">
<h1 class="page"><strong>Lab Guide: Exploring Agentic AI using LlamaStack</strong></h1>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_introduction">1. Introduction</a>
<ul class="sectlevel2">
<li><a href="#_llama_stack">1.1. Llama Stack</a></li>
<li><a href="#_agentic_ai">1.2. Agentic AI</a></li>
<li><a href="#_retrieval_augmented_generation_rag">1.3. Retrieval-Augmented Generation (RAG)</a></li>
<li><a href="#_mcp_server">1.4. MCP Server</a></li>
</ul>
</li>
<li><a href="#_prerequisites">2. Prerequisites</a></li>
<li><a href="#_verify_rhoai_installation">3. Verify RHOAI installation</a></li>
<li><a href="#_setting_up_llama_stack_server_resources">4. Setting Up Llama Stack Server Resources</a>
<ul class="sectlevel2">
<li><a href="#_llama_stack_server_namespace">4.1. Llama Stack Server Namespace</a></li>
<li><a href="#_create_maas_api_keys">4.2. Create MAAS API Keys.</a></li>
<li><a href="#_create_tavily_api_keys">4.3. Create Tavily API Keys.</a></li>
<li><a href="#_llama_stack_server_secret">4.4. Llama stack server secret</a></li>
<li><a href="#_llama_stack_config_map">4.5. Llama stack config map</a></li>
<li><a href="#_llamastackdistribution">4.6. LlamaStackDistribution</a></li>
<li><a href="#_verify_installation">4.7. Verify installation</a></li>
</ul>
</li>
<li><a href="#_exploring_llama_stack_server_apis">5. Exploring Llama stack server APIs</a></li>
<li><a href="#_deploy_the_openshift_mcp_server">6. Deploy the OpenShift MCP Server</a>
<ul class="sectlevel2">
<li><a href="#_openshift_mcp_namespace">6.1. Openshift MCP namespace</a></li>
<li><a href="#_service_account_rolebinding">6.2. Service account &amp; RoleBinding</a></li>
<li><a href="#_deployment">6.3. Deployment</a></li>
<li><a href="#_service">6.4. Service</a></li>
<li><a href="#_exploring_openshift_mcp_via_llama_stack_apis">6.5. Exploring OpenShift MCP via Llama Stack APIs</a></li>
</ul>
</li>
</ul>
</div>
<div id="preamble">
<div class="sectionbody">
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This lab explores the Llama Stack on Red Hat OpenShift AI (RHOAI) included in RHOAI v2.24.
For this its necessary that you apply the rhoai-fast overlay from the AI-Accelerator project during the environment setup.</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/agentic_ai_overlay.png" alt="agentic ai overlay">
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This lab will guide you through setting up this environment and exploring the core concepts of building advanced, multi-component agentic systems. First we are going to setup all relevant components of Llama Stack. Afterwards we are going to create multiple agents, that demonstrate different llama stack capabilities.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a>1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Befor we start with the setup of everything we are going to have a look at the most important tools &amp; technologies, we are going to explore during this lab:</p>
</div>
<div class="sect2">
<h3 id="_llama_stack"><a class="anchor" href="#_llama_stack"></a>1.1. Llama Stack</h3>
<div class="paragraph">
<p>Llama Stack is a comprehensive, open-source framework started at Meta, designed to streamline the creation, deployment, and scaling of generative AI applications. It provides a standardized set of tools and APIs that encompass the entire AI development lifecycle, including inference, fine-tuning, evaluation, safety protocols, and the development of agentic systems capable of complex task execution. By offering a unified interface, Llama Stack aims to simplify the often complex process of integrating advanced AI capabilities into various applications and infrastructures. The core purpose of Llama Stack is to empower developers by reducing friction and complexity, allowing them to focus on building innovative and transformative AI solutions. It codifies best practices within the generative AI ecosystem, offering pre-built tools and support for features like tool calling and retrieval augmented generation (RAG). This standardization facilitates a more consistent development experience, whether deploying locally, on-premises, or in the cloud, and fosters greater interoperability within the rapidly evolving generative AI community. Ultimately, Llama Stack seeks to accelerate the adoption and advancement of generative AI by providing a robust and accessible platform for developers of all sizes.</p>
</div>
<div class="paragraph">
<p>References:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://llama-stack.readthedocs.io/en/latest/">Llama Stack Docs</a></p>
</li>
<li>
<p><a href="https://github.com/opendatahub-io/llama-stack-demos">Llama Stack Demos</a></p>
</li>
<li>
<p><a href="https://www.redhat.com/en/blog/llama-stack-and-case-open-run-anywhere-contract-agents?channel=/en/blog/channel/red-hat-ai">Why do we really need Llama Stack?</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_agentic_ai"><a class="anchor" href="#_agentic_ai"></a>1.2. Agentic AI</h3>
<div class="paragraph">
<p>Traditional AI applications are reactive - they respond to prompts with text. Agentic AI is proactive - it can:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Reason through multi-step problems</p>
</li>
<li>
<p>Plan sequences of actions to achieve goals</p>
</li>
<li>
<p>Act on live systems through secure tool integrations</p>
</li>
<li>
<p>Learn from interactions and improve over time</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Think of it as the difference between a helpful chatbot and an intelligent assistant that can actually get work done.</p>
</div>
<div class="paragraph">
<p>References:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.redhat.com/en/products/ai/agentic-ai">RH Agentic AI</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_retrieval_augmented_generation_rag"><a class="anchor" href="#_retrieval_augmented_generation_rag"></a>1.3. Retrieval-Augmented Generation (RAG)</h3>
<div class="paragraph">
<p>RAG provides a means to supplement the data that exists within an LLM with external knowledge sources of your choosingâ€”such as data repositories, collections of text, and pre-existing documentation. These resources are segmented, indexed in a vector database, and used as reference material to deliver more accurate answers.
RAG is useful because it directs the LLM to retrieve specific, real-time information from your chosen source (or sources) of truth. RAG can save money by providing a custom experience without the expense of model training and fine-tuning. It can also save resources by sending only the most relevant information (rather than lengthy documents) when querying an LLM.</p>
</div>
<div class="paragraph">
<p>References:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.redhat.com/en/topics/ai/what-is-retrieval-augmented-generation">What is RAG?</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_mcp_server"><a class="anchor" href="#_mcp_server"></a>1.4. MCP Server</h3>
<div class="paragraph">
<p>The open-source Model Context Protocol defines a standard way to connect LLMs to nearly any type of external resources like files, APIs, and databases. Itâ€™s built on a client-server system, so applications can easily feed LLMs the context they need.
The OpenShift Model Context Protocol (MCP) Server, which we are going to use in this exercise, lets LLMs interact directly with Kubernetes and OpenShift clusters without needing additional software like kubectl or Helm. It enables operations such as managing pods, viewing logs, installing Helm charts, listing namespaces, etc.â€”all through a unified interface. This server is lightweight and doesnâ€™t require any external dependencies, making it easy to integrate into existing systems. In the advanced level notebooks, we use this server to connect to the OpenShift cluster, check the status of pods running on the cluster, and report their health and activity.</p>
</div>
<div class="paragraph">
<p>References:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://modelcontextprotocol.io/docs/getting-started/intro">MCP Protocol</a></p>
</li>
<li>
<p><a href="https://www.redhat.com/en/blog/model-context-protocol-discover-missing-link-ai-integration">Model Context Protocol: Discover the missing link in AI integration</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_prerequisites"><a class="anchor" href="#_prerequisites"></a>2. Prerequisites</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>You have access to a Red Hat OpenShift AI environment.</p>
</li>
<li>
<p>You have access to <a href="https://red.ht/maas">Model as a Service (MaaS)</a> to get an API token for LLM models.</p>
</li>
<li>
<p>You have access to <a href="https://www.tavily.com/">Tavily</a> to get an API token for the websearch tool.</p>
</li>
<li>
<p>The LlamaStack operator is enabled and running in the cluster.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_verify_rhoai_installation"><a class="anchor" href="#_verify_rhoai_installation"></a>3. Verify RHOAI installation</h2>
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>First check within Openshift Gitops, that the "openshift-ai-operator" application is synched and healthy. <strong>If any of the ai-example-* argocd applications are unhealthy or unsynched, you can ingore them.</strong></p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Verify via oc that the RHOAI is installed in version 2.24.0:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc get clusterserviceversions.operators.coreos.com</code></pre>
</div>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/agentic_ai_clusterserviceversions.png" alt="agentic ai clusterserviceversions">
</div>
</div>
<div class="paragraph">
<p>As we are using verion 2.24.0 the llamastack operator is by default a managed component of RHOAI. This can be verified by looking at the default datasciencecluster:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc get datascienceclusters.datasciencecluster.opendatahub.io -o=jsonpath='{.spec.components}' default | jq</code></pre>
</div>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/agentic_ai_datasciencecluster.png" alt="agentic ai datasciencecluster">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_setting_up_llama_stack_server_resources"><a class="anchor" href="#_setting_up_llama_stack_server_resources"></a>4. Setting Up Llama Stack Server Resources</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_llama_stack_server_namespace"><a class="anchor" href="#_llama_stack_server_namespace"></a>4.1. Llama Stack Server Namespace</h3>
<div class="paragraph">
<p>Save this file as <code>namespace.yaml</code> and apply it using <code>oc apply -f namespace.yaml</code> to create the namespace for the llama stack server:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: llama-stack</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_create_maas_api_keys"><a class="anchor" href="#_create_maas_api_keys"></a>4.2. Create MAAS API Keys.</h3>
<div class="paragraph">
<p>During this lab we are going to use LLMs deployed at RH MAAS:</p>
</div>
<div class="paragraph">
<p>Go to <a href="https://red.ht/maas">Model as a Service (MaaS)</a> and signin using your Red Hat credentials to get an API token for the Llama-3.2-3B as well as Llama-4-Scout-17B-16E-W4A16 models.</p>
</div>
<div class="paragraph">
<p>Your "Apps and API Keys" page should look like the following:</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/agentic_ai_maas.png" alt="agentic ai maas">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_create_tavily_api_keys"><a class="anchor" href="#_create_tavily_api_keys"></a>4.3. Create Tavily API Keys.</h3>
<div class="paragraph">
<p>Go to <a href="https://www.tavily.com/">Tavily</a> to register and create an API token. We will use Tavily for general Web inquiries as it provides API for web searches.</p>
</div>
</div>
<div class="sect2">
<h3 id="_llama_stack_server_secret"><a class="anchor" href="#_llama_stack_server_secret"></a>4.4. Llama stack server secret</h3>
<div class="paragraph">
<p>Next, create a secret to store your API keys. This file defines three separate secrets: two for the different language models (Llama-3.2-3B and Llama-4-Scout-17B-16E-W4A16) and one for the Tavily search tool. Replace the dummy values with your api keys and create the secret within the llama-stack namesapce:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kind: Secret
apiVersion: v1
metadata:
  name: llama-3-2-3b
  namespace: llama-stack
stringData:
  apiKey: &lt;change-me&gt;
type: Opaque
---
kind: Secret
apiVersion: v1
metadata:
  name: llama-4-scout-17b-16e-w4a16
  namespace: llama-stack
stringData:
  apiKey: &lt;change-me&gt;
type: Opaque

---
kind: Secret
apiVersion: v1
metadata:
  name: tavily-search-key
  namespace: llama-stack
stringData:
  apiKey: &lt;change-me&gt;
type: Opaque</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_llama_stack_config_map"><a class="anchor" href="#_llama_stack_config_map"></a>4.5. Llama stack config map</h3>
<div class="paragraph">
<p>Most of the llama stack server configuraiton is done via a yaml file called run.yaml. <a href="https://llamastack.github.io/docs/distributions/configuration">Click here for detailed documentation</a>. When using the operator its stored within a config map.</p>
</div>
<div class="paragraph">
<p>Within the run.yaml we define among others the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>apis:</strong> Which APIs the server will serve.</p>
</li>
<li>
<p><strong>providers:</strong> The most critical part as the providers are the core components to serve the defined apis. This can be seen by the link between other configuration element and the provider ID, which shows whats capability is backed by which provider. This section includes the definitions for our model providers as well as the teavily web search provider.</p>
</li>
<li>
<p><strong>models:</strong> Instances of pre registered models served by a provider.</p>
</li>
<li>
<p><strong>tool_groups:</strong> A tool group represents a set of functions by a single provider that an agent can invoke to perform specific tasks.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Be exicted, we are going to see all the entities defined within this config during the next parts of this lab ðŸ¥³</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Create the <code>ConfigMap</code> for the Llama Stack. Save the following as <code>llama-stack-config.yaml</code>:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: llama-stack-config
  namespace: llama-stack
data:
  run.yaml: |
    # Llama Stack configuration
    version: '2'
    image_name: vllm
    apis:
    - agents
    - inference
    - safety
    - tool_runtime
    - vector_io
    - files
    providers:
      files:
      - provider_id: localfs
        provider_type: inline::localfs
        config:
          storage_dir: /opt/app-root/src/.llama/files
          metadata_store:
            type: sqlite
            db_path: /opt/app-root/src/.llama/files_metadata.db
      vector_io:
      - provider_id: milvus
        provider_type: inline::milvus
        config:
          db_path: /opt/app-root/src/.llama/milvus.db
          kvstore:
            type: sqlite
            db_path: /opt/app-root/src/.llama/milvus_registry.db
      agents:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          persistence_store:
            type: sqlite
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/starter}/agents_store.db
          responses_store:
            type: sqlite
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/starter}/responses_store.db
      inference:
      - provider_id: sentence-transformers
        provider_type: inline::sentence-transformers
        config: {}
      - provider_id: vllm-llama-3-2-3b
        provider_type: "remote::vllm"
        config:
          url: "https://llama-3-2-3b-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1"
          max_tokens: 110000
          api_token: ${env.LLAMA_3_2_3B_API_TOKEN}
          tls_verify: true
      - provider_id: vllm-llama-4-guard
        provider_type: "remote::vllm"
        config:
          url: "https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1"
          max_tokens: 110000
          api_token: ${env.LLAMA_4_SCOUT_17B_16E_W4A16_API_TOKEN}
          tls_verify: true
      tool_runtime:
      - config: {}
        provider_id: rag-runtime
        provider_type: inline::rag-runtime
      - provider_id: model-context-protocol
        provider_type: remote::model-context-protocol
        config: {}
      - provider_id: tavily-search
        provider_type: remote::tavily-search
        config:
          api_key: ${env.TAVILY_API_KEY}
          max_results: 10
    models:
      - metadata: {}
        model_id: llama-3-2-3b
        provider_id: vllm-llama-3-2-3b
        provider_model_id: llama-3-2-3b
        model_type: llm
      - metadata: {}
        model_id: llama-4-scout-17b-16e-w4a16
        provider_id: vllm-llama-4-guard
        provider_model_id: llama-4-scout-17b-16e-w4a16
        model_type: llm
      - metadata:
          embedding_dimension: 768
        model_id: ibm-granite/granite-embedding-125m-english
        provider_id: sentence-transformers
        model_type: embedding
    tools:
      - name: builtin::websearch
        enabled: true
    tool_groups:
    - toolgroup_id: builtin::rag
      provider_id: rag-runtime
      args:
        vector_db_ids: ["default-vector-db"]
    - provider_id: tavily-search
      toolgroup_id: builtin::websearch
    - toolgroup_id: mcp::openshift
      provider_id: model-context-protocol
      mcp_endpoint:
        uri: http://ocp-mcp-server.ocp-mcp.svc.cluster.local:8000/sse
    shields: []
    vector_dbs:
      - vector_db_id: default-vector-db
        provider_id: milvus
        embedding_model: ibm-granite/granite-embedding-125m-english
        embedding_dimension: 768
    datasets: []
    scoring_fns: []
    benchmarks: []
    server:
      port: 8321</code></pre>
</div>
</div>
<div class="paragraph">
<p>Apply the <code>ConfigMap</code> using <code>oc apply -f llama-stack-config.yaml</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_llamastackdistribution"><a class="anchor" href="#_llamastackdistribution"></a>4.6. LlamaStackDistribution</h3>
<div class="paragraph">
<p>Until now we only created static configs/secrets. To create a running llama stack server we will utilize the llama stack operators CR LlamaStackDistribution. In this step we also reference our secret holding the api keys for the external systems. Check again the llama-stack-config ConfigMap to find the environment variable references within the provider definitions.</p>
</div>
<div class="paragraph">
<p>Save the following as <code>llama-stack-distro.yaml</code>:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: llamastack-with-config
  namespace: llama-stack
spec:
  replicas: 1
  server:
    containerSpec:
      env:
      - name: TELEMETRY_SINKS
        value: console, sqlite, otel_trace
      - name: OTEL_TRACE_ENDPOINT
        value: http://otel-collector-collector.observability-hub.svc.cluster.local:4318/v1/traces
      - name: OTEL_METRIC_ENDPOINT
        value: http://otel-collector-collector.observability-hub.svc.cluster.local:4318/v1/metrics
      - name: OTEL_SERVICE_NAME
        value: llamastack
      - name: LLAMA_3_2_3B_API_TOKEN
        valueFrom:
          secretKeyRef:
            key: apiKey
            name: llama-3-2-3b
      - name: LLAMA_4_SCOUT_17B_16E_W4A16_API_TOKEN
        valueFrom:
          secretKeyRef:
            key: apiKey
            name: llama-4-scout-17b-16e-w4a16
      - name: TAVILY_API_KEY
        valueFrom:
          secretKeyRef:
            key: tavily-search-api-key
            name: tavily-search-key
      name: llama-stack
      port: 8321
    distribution:
      # name: rh-dev # due to an error in the current operator version, we pin an older image
      image: registry.redhat.io/rhoai/odh-llama-stack-core-rhel9@sha256:43b60b1ee6f66fec38fe2ffbbe08dca8541ef162332e4bd8e422ecd24ee02646
    storage:
      mountPath: /opt/app-root/src/
      size: 10Gi
    userConfig:
      configMapName: llama-stack-config</code></pre>
</div>
</div>
<div class="paragraph">
<p>Apply the distribution using <code>oc apply -f llama-stack-distro.yaml</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_verify_installation"><a class="anchor" href="#_verify_installation"></a>4.7. Verify installation</h3>
<div class="paragraph">
<p>Validate that the Llama Stack server is running correctly. Check the logs of the pod to ensure that it has successfully connected to the models and the OpenShift MCP server.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc logs -n llama-stack $(oc get pods -n llama-stack -l app=llama-stack -o name | head -n 1)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Look for the message "Application startup complete":</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/agentic_llamastackserver_startup.png" alt="agentic llamastackserver startup">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Llama stack server is ready to go!</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_exploring_llama_stack_server_apis"><a class="anchor" href="#_exploring_llama_stack_server_apis"></a>5. Exploring Llama stack server APIs</h2>
<div class="sectionbody">
<div class="paragraph">
<p>By its core llama stack is a set of apis. As the llama stack server comes with a swagger ui, its easy to investigate its apis via the browser.</p>
</div>
<div class="paragraph">
<p>As the llama stack server is not exposed to the outside of the cluster, lets create a local port forward for the service:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc port-forward services/llamastack-with-config-service 8321:localhost:8321 -n llama-stack</code></pre>
</div>
</div>
<div class="paragraph">
<p>Open <code><a href="http://localhost:8321/docs#" class="bare">http://localhost:8321/docs#</a></code> on a browser of your choice.</p>
</div>
<div class="paragraph">
<p>You should see the following swagger ui:</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/agentic_ai_swagger.png" alt="agentic ai swagger">
</div>
</div>
<div class="paragraph">
<p>Try to find the following information using the swagger ui:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Which models are registered on the server?</p>
</li>
<li>
<p>What tool groups are registered on the server?</p>
</li>
<li>
<p>Which tools are provided by the builtin::websearch tool group?</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deploy_the_openshift_mcp_server"><a class="anchor" href="#_deploy_the_openshift_mcp_server"></a>6. Deploy the OpenShift MCP Server</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To finish the lab setup, we are going to deploy an instance of the Openshift MCP server. The OpenShift Model Context Protocol (MCP) server acts as a bridge, allowing the Llama Stack agent to interact with the OpenShift cluster to answer questions about its state.</p>
</div>
<div class="sect2">
<h3 id="_openshift_mcp_namespace"><a class="anchor" href="#_openshift_mcp_namespace"></a>6.1. Openshift MCP namespace</h3>
<div class="paragraph">
<p>First, create a new namespace for the MCP server:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: ocp-mcp</code></pre>
</div>
</div>
<div class="paragraph">
<p>Save this file as <code>ocp-mcp-namespace.yaml</code> and apply it using <code>oc apply -f ocp-mcp-namespace.yaml</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_service_account_rolebinding"><a class="anchor" href="#_service_account_rolebinding"></a>6.2. Service account &amp; RoleBinding</h3>
<div class="paragraph">
<p>Next, create a <code>ServiceAccount</code> and the necessary <code>RoleBinding</code> and <code>ClusterRoleBinding</code> to grant it permissions to read resources from the cluster.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: ocp-mcp
  namespace: ocp-mcp
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ocp-mcp
  namespace: ocp-mcp
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: edit
subjects:
- kind: ServiceAccount
  name: ocp-mcp
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-admin-ocp-mcp
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: ocp-mcp
  namespace: ocp-mcp</code></pre>
</div>
</div>
<div class="paragraph">
<p>Save this file as <code>ocp-mcp-sa.yaml</code> and apply it using <code>oc apply -f ocp-mcp-sa.yaml</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_deployment"><a class="anchor" href="#_deployment"></a>6.3. Deployment</h3>
<div class="paragraph">
<p>Now, create the <code>Deployment</code> for the MCP server.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: ocp-mcp-server
  name: ocp-mcp-server
  namespace: ocp-mcp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ocp-mcp-server
  template:
    metadata:
      labels:
        app: ocp-mcp-server
        deployment: ocp-mcp-server
    spec:
      containers:
      - name: ocp-mcp-server
        args:
        - --sse-port
        - "8000"
        command:
        - ./kubernetes-mcp-server
        # K8s mcp server image from rh etx
        image: quay.io/eformat/kubernetes-mcp-server:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        resources: {}
      serviceAccountName: ocp-mcp</code></pre>
</div>
</div>
<div class="paragraph">
<p>Save this file as <code>ocp-mcp-deployment.yaml</code> and apply it using <code>oc apply -f ocp-mcp-deployment.yaml</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_service"><a class="anchor" href="#_service"></a>6.4. Service</h3>
<div class="paragraph">
<p>Finally, create the <code>Service</code> to expose the MCP server within the cluster.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  labels:
    app: ocp-mcp-server
  name: ocp-mcp-server
spec:
  ports:
  - port: 8000
    protocol: TCP
    targetPort: http
  selector:
    app: ocp-mcp-server
    deployment: ocp-mcp-server</code></pre>
</div>
</div>
<div class="paragraph">
<p>Save this file as <code>ocp-mcp-service.yaml</code> and apply it using <code>oc apply -f ocp-mcp-service.yaml</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_exploring_openshift_mcp_via_llama_stack_apis"><a class="anchor" href="#_exploring_openshift_mcp_via_llama_stack_apis"></a>6.5. Exploring OpenShift MCP via Llama Stack APIs</h3>
<div class="paragraph">
<p>Use the llama stack swagger ui to explore:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>What tools does the OpenShift MCP tool group offer?</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <a href="https://demo.redhat.com" target="_blank" class="poweredBy"><p>Powered by</p><div class="labInfo_poweredBy" style="display: block; width: 260px;"><svg class="labInfo_poweredByLogo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1508.5 178.739"><g fill="#111"><path d="M316.6 63.2v-56H342a21.279 21.279 0 0 1 7.8 1.3 18.111 18.111 0 0 1 5.9 3.5 15.577 15.577 0 0 1 5 11.8 15.051 15.051 0 0 1-3.1 9.5 16.836 16.836 0 0 1-8.4 5.8l12.5 24.1h-9.3l-11.6-23H325v23Zm24.7-48.6H325v18.7h16.3q5.25 0 8.1-2.7a8.7 8.7 0 0 0 2.8-6.6 8.7 8.7 0 0 0-2.8-6.6c-1.8-1.9-4.5-2.8-8.1-2.8ZM364.1 42.8a20.674 20.674 0 0 1 1.6-8.2 20.288 20.288 0 0 1 4.3-6.7 19.92 19.92 0 0 1 6.5-4.5 19.718 19.718 0 0 1 8-1.6 18.463 18.463 0 0 1 7.8 1.6 18.677 18.677 0 0 1 6.2 4.5 20.927 20.927 0 0 1 4.1 6.8 23.2 23.2 0 0 1 1.5 8.4v2.3H372a13.822 13.822 0 0 0 4.6 8.4 13.6 13.6 0 0 0 9.1 3.3 15.553 15.553 0 0 0 5.7-1 12.858 12.858 0 0 0 4.6-2.6l5.1 5a25.983 25.983 0 0 1-7.4 4.1 24.69 24.69 0 0 1-8.4 1.3 21.306 21.306 0 0 1-8.4-1.6 22.763 22.763 0 0 1-6.8-4.4 20.788 20.788 0 0 1-4.5-6.7 23.2 23.2 0 0 1-1.5-8.4Zm20.2-14.2a11.527 11.527 0 0 0-8 3 13.046 13.046 0 0 0-4.2 7.8h24.2a13.091 13.091 0 0 0-4.2-7.8 11.106 11.106 0 0 0-7.8-3ZM443.1 63.2v-3.8a19.448 19.448 0 0 1-5.8 3.3 18.924 18.924 0 0 1-6.7 1.2 19.824 19.824 0 0 1-14.6-6.1 22.268 22.268 0 0 1-4.4-6.7 21.812 21.812 0 0 1 0-16.4A20.534 20.534 0 0 1 416 28a19.335 19.335 0 0 1 6.6-4.5 20.334 20.334 0 0 1 8.2-1.6 20.7 20.7 0 0 1 6.6 1 19.415 19.415 0 0 1 5.7 3V7.2l8-1.8v57.8Zm-25.2-20.4a13.718 13.718 0 0 0 4 10.1 13.45 13.45 0 0 0 9.8 4.1 14.956 14.956 0 0 0 6.4-1.3 15.954 15.954 0 0 0 4.9-3.6V33.6a14.988 14.988 0 0 0-4.9-3.5 15.271 15.271 0 0 0-6.4-1.3 13.423 13.423 0 0 0-9.9 4 13.806 13.806 0 0 0-3.9 10ZM478.1 63.2v-56h8.4v24h29.8v-24h8.4v56h-8.4V38.8h-29.8v24.4ZM547.2 64a16.483 16.483 0 0 1-10.8-3.5 11.037 11.037 0 0 1-4.2-8.9 10.375 10.375 0 0 1 4.7-9.2 20.76 20.76 0 0 1 11.8-3.2 27.841 27.841 0 0 1 5.8.6 27.374 27.374 0 0 1 5.3 1.6v-4.3a8.143 8.143 0 0 0-2.6-6.5 11.452 11.452 0 0 0-7.4-2.2 20.788 20.788 0 0 0-6 .9 34.616 34.616 0 0 0-6.6 2.6l-3-6a54.169 54.169 0 0 1 8.4-3.1 33.18 33.18 0 0 1 8.3-1.1c5.2 0 9.3 1.3 12.2 3.8s4.4 6.1 4.4 10.8v27h-7.8v-3.5a19.441 19.441 0 0 1-5.8 3.2 23.54 23.54 0 0 1-6.7 1Zm-7.3-12.6a5.646 5.646 0 0 0 2.6 4.8 11.193 11.193 0 0 0 6.6 1.8 16.256 16.256 0 0 0 5.9-1 14.449 14.449 0 0 0 4.9-2.9V47a19.778 19.778 0 0 0-4.8-1.8 24.933 24.933 0 0 0-5.7-.6 11.859 11.859 0 0 0-6.8 1.8 5.728 5.728 0 0 0-2.7 5ZM580.6 53.2v-24H572v-6.7h8.6V12.1l7.9-1.9v12.3h12v6.7h-12v22.1a5.94 5.94 0 0 0 1.4 4.4c.9.9 2.5 1.3 4.6 1.3a23.637 23.637 0 0 0 3-.2 10.857 10.857 0 0 0 2.8-.8v6.7a19.28 19.28 0 0 1-3.8.9 27.484 27.484 0 0 1-3.8.3c-3.9 0-7-.9-9-2.8-2-1.7-3.1-4.4-3.1-7.9Z"></path></g><path d="M127 90.2c12.5 0 30.6-2.6 30.6-17.5a12.678 12.678 0 0 0-.3-3.4L149.8 37c-1.7-7.1-3.2-10.3-15.7-16.6-9.7-5-30.8-13.1-37.1-13.1-5.8 0-7.5 7.5-14.4 7.5-6.7 0-11.6-5.6-17.9-5.6-6 0-9.9 4.1-12.9 12.5 0 0-8.4 23.7-9.5 27.2a4.216 4.216 0 0 0-.3 1.9c0 9.2 36.3 39.4 85 39.4Zm32.5-11.4c1.7 8.2 1.7 9.1 1.7 10.1 0 14-15.7 21.8-36.4 21.8-46.8 0-87.7-27.4-87.7-45.5a17.535 17.535 0 0 1 1.5-7.3C21.8 58.8 0 61.8 0 81c0 31.5 74.6 70.3 133.7 70.3 45.3 0 56.7-20.5 56.7-36.6-.1-12.8-11-27.3-30.9-35.9Z" fill="#e00"></path><path d="M159.5 78.8c1.7 8.2 1.7 9.1 1.7 10.1 0 14-15.7 21.8-36.4 21.8-46.8 0-87.7-27.4-87.7-45.5a17.535 17.535 0 0 1 1.5-7.3l3.7-9.1a4.877 4.877 0 0 0-.3 2c0 9.2 36.3 39.4 85 39.4 12.5 0 30.6-2.6 30.6-17.5a12.678 12.678 0 0 0-.3-3.4Z"></path><path d="M253.5 158.7a2.22 2.22 0 0 1-2.2-2.2V2.2a2.2 2.2 0 0 1 4.4 0v154.2a2.242 2.242 0 0 1-2.2 2.3Z" fill="#111"></path><text data-name="Demo Platform" transform="translate(1186 149)" fill="#111" font-size="82" font-family="'RedHatDisplay', 'Overpass', overpass, helvetica, arial, sans-serif" font-weight="700"><tspan x="-877.892" y="0">Demo Platform</tspan></text></svg></div></a>
</footer>
<script src="../_/js/vendor/clipboard.js"></script>
<script src="../_/js/site.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>
  </body>
</html>
