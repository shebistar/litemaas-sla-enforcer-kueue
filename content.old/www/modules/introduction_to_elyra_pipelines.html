<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Introduction to Elyra Pipelines :: Platform Foundation Bootcamp - RHOAI</title>
    <link rel="canonical" href="https://redhat-ai-services.github.io/rhoai-platform-foundation-bootcamp-instructions/modules/introduction_to_elyra_pipelines.html">
    <meta name="generator" content="Antora 3.1.14">
<link rel="stylesheet" href="../_/css/site.css"><link rel="stylesheet" href="../_/css/site-extra.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<meta name="robots" content="all">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://demo.redhat.com/images/favicon.ico" type="image/x-icon">
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar"  style="background-color: #131313 !important;">
    <div class="navbar-brand">
      <div style="display: flex; flex-direction:row; padding: 12px 32px; gap: 16px;">
     </div>
      <div class="navbar-item site-title" style="color: #fff !important;flex: 1;">Platform Foundation Bootcamp - RHOAI</div>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="modules" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title" style="display: none;"><a href="index.html" class=" query-params-link">Navigation</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="01_welcome.html">Welcome and Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="05_environment_provisioning.html">Environment Provisioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">AI-Accelerator</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="20_ai-accelerator_review.html">Project Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="07_installation.html">Bootstrap Installation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="30_gitops_env_setup_dev_prod.html">Setup Dev &amp; Prod Environments</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">RHOAI Administration</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="32_dashboard_configuration.html">RHOAI Dashboard Configuration</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Notebooks</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="31_custom_notebook.html">Custom Notebook</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="09_remote_connect_notebook.html">Connect to Workbench Kernel</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Train, Store (S3), Deploy</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="33_model_training_car.html">Model Training</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="34_using_s3_storage.html">Using S3 Storage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="36_deploy_model.html">Deploy Model</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Data Science Pipelines</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="40_setup_pipeline_server.html">Setup Pipeline Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="41_introduction_to_kfp_pipelines.html">KFP Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="kfp_elyra_differences.html">Comparison between Elyra and KFP</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="build_custom_runtime_image.html">Custom Runtime Image</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="introduction_to_elyra_pipelines.html">Elyra Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="42_working_with_pipelines.html">Working with Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="43_custom_runtime_image.html">Advanced Pipeline Customization</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Distributed Training</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="50_distributed_training.html">Ray Cluster</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Large Language Model [LLM]</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="60_llm_explore.html">Explore LLMs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="70_rag_llm.html">RAG with LLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="composer_ai.html">Composer AI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Monitoring Data Science Models</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="80_trustyai_overview.html">TrustyAI Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="81_llm_evaluation.html">Evaluating Large Language Models</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Disconnected Environment</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="disconnected_install.html">RHOAI on Disconnected Environment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">GPU as a Service</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="90_environment_provisioning.html">Provisioning a GPU Environment with NVIDIA A10G Tensor Core GPU</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="91_gpu_as_a_service_intro.html">Introduction: GPU as a Service with GPU slicing and Kueue</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="92_nvidia_gpu_operator.html">Configuring NVIDIA GPU Time-Slicing on OpenShift</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="93_kueue_setup.html">Red Hat build of Kueue Operator Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="94_kueue_gpu_pricing_tier.html">Implementing GPU Pricing Tiers with Kueue</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="95_kueue_fair_sharing.html">Advanced GPU Quota Management and Preemption with Kueue</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Model-as-a-Service</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="100_maas_intro.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="101_maas_bootstrap.html">Environment Bootstrap</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="102_maas_as_developer.html">Using MaaS as Developer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="103_maas_as_platform_engineer.html">Configure a new model</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="104_maas_monitor.html">Monitor usage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Agentic AI with Llama Stack</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="97_agentic_ai_llama_stack_introduction.html">Introduction &amp; Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="98_agentic_ai_llama_stack_notebook_agents.html">Agentic AI Agents with Llama Stack Clients</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="99_agentic_ai_llama_stack_playground.html">Llama Stack Playground</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="#99_useful_tips.adoc">Useful Tips</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="#97_syncing_fork.adoc">Syncing Forked Project</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Navigation</span>
      <ul class="versions">
        <li class="version is-current">
          <a href="index.html">default</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="01_welcome.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li>Data Science Pipelines</li>
    <li><a href="introduction_to_elyra_pipelines.html">Elyra Pipelines</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<article class="doc">
<h1 class="page">Introduction to Elyra Pipelines</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>In this section, we learn about elyra pipelines. Elyra pipelines are a way to orchestrate and manage machine learning workflows. They provide a structured approach to defining and executing tasks in a sequential manner. Elyra pipelines can be created using a visual editor, making it easy for users to design and customize their workflows.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_elyra_runtime_configuration_in_jupyter_notebooks"><a class="anchor" href="#_elyra_runtime_configuration_in_jupyter_notebooks"></a>Elyra Runtime Configuration in Jupyter Notebooks</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In OpenShift AI, you can manage runtime configurations using the JupyterLab UI.</p>
</div>
<div class="paragraph">
<p>A runtime configuration provides Elyra access to the Data Science Pipelines backend for scalable pipeline execution.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
The runtime configuration is included and is pre-configured for submitting pipelines to Data Science Pipelines <strong>only when the pipeline server is created in the project before the workbench is created.</strong>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_creating_a_data_science_pipeline_with_elyra"><a class="anchor" href="#_creating_a_data_science_pipeline_with_elyra"></a>Creating a Data Science Pipeline with Elyra</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create a new directory named <code>data</code> in the root folder and upload the following files (test.csv, train.csv,validate.csv) You can download the file by clicking the link below:</p>
<div class="paragraph">
<p><a href="https://github.com/rh-aiservices-bu/fraud-detection/blob/main/data/test.csv">Download test.csv</a></p>
</div>
<div class="paragraph">
<p><a href="https://github.com/rh-aiservices-bu/fraud-detection/blob/main/data/train.csv">Download train.csv</a></p>
</div>
<div class="paragraph">
<p><a href="https://github.com/rh-aiservices-bu/fraud-detection/blob/main/data/validate.csv">Download validate.csv</a></p>
</div>
</li>
</ol>
</div>
<div class="sect2">
<h3 id="_create_notebook_to_train_a_model"><a class="anchor" href="#_create_notebook_to_train_a_model"></a>Create notebook to train a model</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Open the <code>standard-workbench</code> in <code>parasol-insurance</code> project. Click on Launcher and create a new python notebook <code>1.train_model.ipynb</code></p>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/notebook.png" alt="notebook">
</div>
</div>
</li>
<li>
<p>Add the following content to <code>1.train_model.ipynb</code> notebook.</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">!pip install onnx==1.17.0 onnxruntime==1.20.1 tf2onnx==1.16.1 keras tensorflow</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import numpy as np
import pandas as pd
import datetime
from keras.models import Sequential
from keras.layers import Dense, Dropout, BatchNormalization, Activation
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils import class_weight
import tf2onnx
import onnx
import pickle
from pathlib import Path</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Set the input (X) and output (Y) data.
# The only output data is whether it's fraudulent. All other fields are inputs to the model.

feature_indexes = [
    1,  # distance_from_last_transaction
    2,  # ratio_to_median_purchase_price
    4,  # used_chip
    5,  # used_pin_number
    6,  # online_order
]

label_indexes = [
    7  # fraud
]

df = pd.read_csv('data/train.csv')
X_train = df.iloc[:, feature_indexes].values
y_train = df.iloc[:, label_indexes].values

df = pd.read_csv('data/validate.csv')
X_val = df.iloc[:, feature_indexes].values
y_val = df.iloc[:, label_indexes].values

df = pd.read_csv('data/test.csv')
X_test = df.iloc[:, feature_indexes].values
y_test = df.iloc[:, label_indexes].values


# Scale the data to remove mean and have unit variance. The data will be between -1 and 1, which makes it a lot easier for the model to learn than random (and potentially large) values.
# It is important to only fit the scaler to the training data, otherwise you are leaking information about the global distribution of variables (which is influenced by the test set) into the training set.

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

Path("artifact").mkdir(parents=True, exist_ok=True)
with open("artifact/test_data.pkl", "wb") as handle:
    pickle.dump((X_test, y_test), handle)
with open("artifact/scaler.pkl", "wb") as handle:
    pickle.dump(scaler, handle)

# Since the dataset is unbalanced (it has many more non-fraud transactions than fraudulent ones), set a class weight to weight the few fraudulent transactions higher than the many non-fraud transactions.
class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.ravel())
class_weights = {i : class_weights[i] for i in range(len(class_weights))}</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">model = Sequential()
model.add(Dense(32, activation='relu', input_dim=len(feature_indexes)))
model.add(Dropout(0.2))
model.add(Dense(32))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(32))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Train the model and get performance
import os
import time

start = time.time()
epochs = 2
history = model.fit(
    X_train,
    y_train,
    epochs=epochs,
    validation_data=(X_val, y_val),
    verbose=True,
    class_weight=class_weights
)
end = time.time()
print(f"Training of model is complete. Took {end-start} seconds")</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">#Save the model
import tensorflow as tf

# Normally we use tf2.onnx.convert.from_keras.
# workaround for tf2onnx bug https://github.com/onnx/tensorflow-onnx/issues/2348

# Wrap the model in a `tf.function`
@tf.function(input_signature=[tf.TensorSpec([None, X_train.shape[1]], tf.float32, name='dense_input')])
def model_fn(x):
    return model(x)

# Convert the Keras model to ONNX
model_proto, _ = tf2onnx.convert.from_function(
    model_fn,
    input_signature=[tf.TensorSpec([None, X_train.shape[1]], tf.float32, name='dense_input')]
)

# Save the model as ONNX for easy use of ModelMesh
os.makedirs("models/fraud/1", exist_ok=True)
onnx.save(model_proto, "models/fraud/1/model.onnx")</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">! ls -alRh ./models/</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">#Test the model
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import pickle
import onnxruntime as rt</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">with open('artifact/scaler.pkl', 'rb') as handle:
    scaler = pickle.load(handle)
with open('artifact/test_data.pkl', 'rb') as handle:
    (X_test, y_test) = pickle.load(handle)</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">sess = rt.InferenceSession("models/fraud/1/model.onnx", providers=rt.get_available_providers())
input_name = sess.get_inputs()[0].name
output_name = sess.get_outputs()[0].name
y_pred_temp = sess.run([output_name], {input_name: X_test.astype(np.float32)})
y_pred_temp = np.asarray(np.squeeze(y_pred_temp[0]))
threshold = 0.95
y_pred = np.where(y_pred_temp &gt; threshold, 1, 0)</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from sklearn.metrics import precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay
import numpy as np

y_test_arr = y_test.squeeze()
correct = np.equal(y_pred, y_test_arr).sum().item()
acc = (correct / len(y_pred)) * 100
precision = precision_score(y_test_arr, np.round(y_pred))
recall = recall_score(y_test_arr, np.round(y_pred))

print(f"Eval Metrics: \n Accuracy: {acc:&gt;0.1f}%, "
      f"Precision: {precision:.4f}, Recall: {recall:.4f} \n")

c_matrix = confusion_matrix(y_test_arr, y_pred)
ConfusionMatrixDisplay(c_matrix).plot()</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">sally_transaction_details = [
    [0.3111400080477545,
    1.9459399775518593,
    1.0,
    0.0,
    0.0]
    ]

prediction = sess.run([output_name], {input_name: scaler.transform(sally_transaction_details).astype(np.float32)})

print("Is Sally's transaction predicted to be fraudulent? (true = YES, false = NO) ")
print(np.squeeze(prediction) &gt; threshold)

print("How likely was Sally's transaction to be fraudulent? ")
print("{:.5f}".format(100 * np.squeeze(prediction)) + "%")</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_create_a_new_notebook_to_save_the_model"><a class="anchor" href="#_create_a_new_notebook_to_save_the_model"></a>Create a new notebook to save the model</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create a new jupyter notebook  <code>2.save_model.ipynb</code> and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">!pip install boto3==1.35.55 botocore==1.35.55</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import os
import boto3
import botocore

aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')
aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')
endpoint_url = os.environ.get('AWS_S3_ENDPOINT')
region_name = os.environ.get('AWS_DEFAULT_REGION')
bucket_name = os.environ.get('AWS_S3_BUCKET')

print(f"{aws_access_key_id}")


if not all([aws_access_key_id, aws_secret_access_key, endpoint_url, region_name, bucket_name]):
    raise ValueError("One or more connection variables are empty.  "
                     "Please check your connection to an S3 bucket.")

session = boto3.session.Session(aws_access_key_id=aws_access_key_id,
                                aws_secret_access_key=aws_secret_access_key)

s3_resource = session.resource(
    's3',
    config=botocore.client.Config(signature_version='s3v4'),
    endpoint_url=endpoint_url,
    region_name=region_name)

bucket = s3_resource.Bucket(bucket_name)


def upload_directory_to_s3(local_directory, s3_prefix):
    num_files = 0
    for root, dirs, files in os.walk(local_directory):
        for filename in files:
            file_path = os.path.join(root, filename)
            relative_path = os.path.relpath(file_path, local_directory)
            s3_key = os.path.join(s3_prefix, relative_path)
            print(f"{file_path} -&gt; {s3_key}")
            bucket.upload_file(file_path, s3_key)
            num_files += 1
    return num_files


def list_objects(prefix):
    filter = bucket.objects.filter(Prefix=prefix)
    for obj in filter.all():
        print(obj.key)</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Updated custom notebook.yaml to avoid storage related errors.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kubeflow.org/v1
kind: Notebook
metadata:
  annotations:
    notebooks.opendatahub.io/inject-oauth: 'true'
    opendatahub.io/image-display-name: Datascience notebook
    notebooks.opendatahub.io/oauth-logout-url: ''
    opendatahub.io/accelerator-name: ''
    openshift.io/description: ''
    openshift.io/display-name: custom-workbench
    notebooks.opendatahub.io/last-image-selection: 'custom-notebook:latest'
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: custom-workbench
  namespace: parasol-insurance
spec:
  template:
    spec:
      affinity: {}
      containers:
        - name: custom-workbench
          image: 'image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/custom-notebook:latest'
          resources:
            limits:
              cpu: '2'
              memory: 8Gi
            requests:
              cpu: '1'
              memory: 8Gi
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /notebook/parasol-insurance/custom-workbench/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /notebook/parasol-insurance/custom-workbench/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          env:
            - name: NOTEBOOK_ARGS
              value: |-
                --ServerApp.port=8888
                --ServerApp.token=''
                --ServerApp.password=''
                --ServerApp.base_url=/notebook/parasol-insurance/custom-workbench
                --ServerApp.quit_button=False
                --ServerApp.tornado_settings={"user":"user1","hub_host":"","hub_prefix":"/projects/parasol-insurance"}
            - name: JUPYTER_IMAGE
              value: 'image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/custom-notebook:latest'
            - name: PIPELINES_SSL_SA_CERTS
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: GIT_SSL_CAINFO
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: PIP_CERT
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: REQUESTS_CA_BUNDLE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: SSL_CERT_FILE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
          ports:
            - containerPort: 8888
              name: notebook-port
              protocol: TCP
          imagePullPolicy: Always
          volumeMounts:
            - mountPath: /opt/app-root/src
              name: custom-workbench
            - mountPath: /dev/shm
              name: shm
            - mountPath: /etc/pki/tls/custom-certs/ca-bundle.crt
              name: trusted-ca
              readOnly: true
              subPath: ca-bundle.crt
          workingDir: /opt/app-root/src
          envFrom:
            - secretRef:
                name: minio-data-connection
      enableServiceLinks: false
      serviceAccountName: custom-workbench
      volumes:
        - name: custom-workbench
          persistentVolumeClaim:
            claimName: custom-workbench
        - emptyDir:
            medium: Memory
          name: shm
        - configMap:
            items:
              - key: ca-bundle.crt
                path: ca-bundle.crt
            name: workbench-trusted-ca-bundle
            optional: true
          name: trusted-ca</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Updated minio-data-connection.yaml to avoid storage related errors.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kind: Secret
apiVersion: v1
metadata:
  name: minio-data-connection
  labels:
    opendatahub.io/dashboard: 'true'
    opendatahub.io/managed: 'true'
  annotations:
    opendatahub.io/connection-type: s3
    openshift.io/display-name: minio-data-connection
    argocd.argoproj.io/sync-wave: "-100"
stringData:
  AWS_ACCESS_KEY_ID: minio
  AWS_S3_ENDPOINT: http://minio.object-datastore.svc.cluster.local:9000
  AWS_SECRET_ACCESS_KEY: minio123
  AWS_DEFAULT_REGION: east-1
  AWS_S3_BUCKET: pipelines
type: Opaque</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">list_objects("models")</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">local_models_directory = "models"

if not os.path.isdir(local_models_directory):
    raise ValueError(f"The directory '{local_models_directory}' does not exist.  "
                     "Did you finish training the model in the previous notebook?")

num_files = upload_directory_to_s3("models", "models")

if num_files == 0:
    raise ValueError("No files uploaded.  Did you finish training and "
                     "saving the model to the \"models\" directory?  "
                     "Check for \"models/fraud/1/model.onnx\"")</code></pre>
</div>
</div>
</li>
<li>
<p>Add a new cell and add the following content:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">list_objects("models")</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_create_a_pipeline_using_elyra_pipeline_editor"><a class="anchor" href="#_create_a_pipeline_using_elyra_pipeline_editor"></a>Create a pipeline using Elyra pipeline editor</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Click on <code>Pipeline Editor</code> and create a new pipeline. Name the pipeline as <code>train_save.pipeline`</code></p>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/pipeline_editor.png" alt="pipeline editor">
</div>
</div>
</li>
<li>
<p>Drag and drop two notebooks just created (<code>1.train_model</code> and   <code>2.save_model</code>) into the pipeline editor.</p>
</li>
<li>
<p>Connect the output port of node <code>1.train_model</code> to the input port of node <code>2.save_model</code>.</p>
</li>
<li>
<p>Update the pipeline parameters for node 1.train_model.</p>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/pipeline_parameters.png" alt="pipeline parameters">
</div>
</div>
</li>
<li>
<p>Update the runtime image for both nodes to <code>Datascience with Python 3.11 (UBI9)</code> created in the previous section.</p>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/elyra_runtime.png" alt="elyra runtime">
</div>
</div>
</li>
<li>
<p>Update S3 storage <code>Kubernetes Secrets</code> for node 2.save_model</p>
<div class="listingblock">
<div class="title">Solution</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">AWS_ACCESS_KEY_ID: &lt;AWS_ACCESS_KEY_ID&gt;
AWS_SECRET_ACCESS_KEY: &lt;AWS_SECRET_ACCESS_KEY&gt;
AWS_S3_BUCKET: &lt;AWS_S3_BUCKET&gt;
AWS_S3_ENDPOINT: &lt;AWS_S3_ENDPOINT&gt;
AWS_DEFAULT_REGION: &lt;AWS_DEFAULT_REGION&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>Click on Run icon to run the pipeline. Pipline run can be viewed on RHOAI dashboard.</p>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/elyra_run_pipeline.png" alt="elyra run pipeline">
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_pipeline_execution"><a class="anchor" href="#_pipeline_execution"></a>Pipeline execution</h3>
<div class="paragraph">
<p>Elyra is now converting your pipeline definition into a YAML representation and sending it to the Data Science Pipelines backend. After a few seconds, you should see confirmation that the pipeline has been successfully submitted.</p>
</div>
<div class="paragraph">
<p>To monitor the pipeline&#8217;s execution, click on the <code><em>Run Details</em></code> link, which takes you to the pipeline run view within the RHOAI dashboard. Here you can track in real-time how each pipeline task is processed and whether it fails or resolves successfully.</p>
</div>
<div class="paragraph">
<p>To confirm that the pipeline has indeed produced fraud detection scoring results, view the content of the pipeline storage bucket. In the folder, there will be HTML files that show the status of each of the task executions.</p>
</div>
<div class="paragraph">
<p>Navigate back to the <code>Experiment and Runs</code> overview in the RHOAI dashboard. Click the experiment to see the history of all ongoing and previous pipeline executions of the same name and compare their run durations and status.</p>
</div>
<div class="paragraph">
<p>In the <code>Scheduled</code> tab you&#8217;re able to view runs of the pipeline according to a predefined schedule such as daily or according to a Cron statement.</p>
</div>
</div>
<div class="sect2">
<h3 id="_questions_for_further_consideration"><a class="anchor" href="#_questions_for_further_consideration"></a>Questions for Further Consideration</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Will all the upstream Elyra features be avaiable on RHOAI?</p>
</li>
<li>
<p>How can you implement error handling strategies within your pipelines to manage failures effectively?</p>
</li>
<li>
<p>What techniques can be employed to optimize the performance of pipelines, especially when dealing with large datasets?</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <a href="https://demo.redhat.com" target="_blank" class="poweredBy"><p>Powered by</p><div class="labInfo_poweredBy" style="display: block; width: 260px;"><svg class="labInfo_poweredByLogo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1508.5 178.739"><g fill="#111"><path d="M316.6 63.2v-56H342a21.279 21.279 0 0 1 7.8 1.3 18.111 18.111 0 0 1 5.9 3.5 15.577 15.577 0 0 1 5 11.8 15.051 15.051 0 0 1-3.1 9.5 16.836 16.836 0 0 1-8.4 5.8l12.5 24.1h-9.3l-11.6-23H325v23Zm24.7-48.6H325v18.7h16.3q5.25 0 8.1-2.7a8.7 8.7 0 0 0 2.8-6.6 8.7 8.7 0 0 0-2.8-6.6c-1.8-1.9-4.5-2.8-8.1-2.8ZM364.1 42.8a20.674 20.674 0 0 1 1.6-8.2 20.288 20.288 0 0 1 4.3-6.7 19.92 19.92 0 0 1 6.5-4.5 19.718 19.718 0 0 1 8-1.6 18.463 18.463 0 0 1 7.8 1.6 18.677 18.677 0 0 1 6.2 4.5 20.927 20.927 0 0 1 4.1 6.8 23.2 23.2 0 0 1 1.5 8.4v2.3H372a13.822 13.822 0 0 0 4.6 8.4 13.6 13.6 0 0 0 9.1 3.3 15.553 15.553 0 0 0 5.7-1 12.858 12.858 0 0 0 4.6-2.6l5.1 5a25.983 25.983 0 0 1-7.4 4.1 24.69 24.69 0 0 1-8.4 1.3 21.306 21.306 0 0 1-8.4-1.6 22.763 22.763 0 0 1-6.8-4.4 20.788 20.788 0 0 1-4.5-6.7 23.2 23.2 0 0 1-1.5-8.4Zm20.2-14.2a11.527 11.527 0 0 0-8 3 13.046 13.046 0 0 0-4.2 7.8h24.2a13.091 13.091 0 0 0-4.2-7.8 11.106 11.106 0 0 0-7.8-3ZM443.1 63.2v-3.8a19.448 19.448 0 0 1-5.8 3.3 18.924 18.924 0 0 1-6.7 1.2 19.824 19.824 0 0 1-14.6-6.1 22.268 22.268 0 0 1-4.4-6.7 21.812 21.812 0 0 1 0-16.4A20.534 20.534 0 0 1 416 28a19.335 19.335 0 0 1 6.6-4.5 20.334 20.334 0 0 1 8.2-1.6 20.7 20.7 0 0 1 6.6 1 19.415 19.415 0 0 1 5.7 3V7.2l8-1.8v57.8Zm-25.2-20.4a13.718 13.718 0 0 0 4 10.1 13.45 13.45 0 0 0 9.8 4.1 14.956 14.956 0 0 0 6.4-1.3 15.954 15.954 0 0 0 4.9-3.6V33.6a14.988 14.988 0 0 0-4.9-3.5 15.271 15.271 0 0 0-6.4-1.3 13.423 13.423 0 0 0-9.9 4 13.806 13.806 0 0 0-3.9 10ZM478.1 63.2v-56h8.4v24h29.8v-24h8.4v56h-8.4V38.8h-29.8v24.4ZM547.2 64a16.483 16.483 0 0 1-10.8-3.5 11.037 11.037 0 0 1-4.2-8.9 10.375 10.375 0 0 1 4.7-9.2 20.76 20.76 0 0 1 11.8-3.2 27.841 27.841 0 0 1 5.8.6 27.374 27.374 0 0 1 5.3 1.6v-4.3a8.143 8.143 0 0 0-2.6-6.5 11.452 11.452 0 0 0-7.4-2.2 20.788 20.788 0 0 0-6 .9 34.616 34.616 0 0 0-6.6 2.6l-3-6a54.169 54.169 0 0 1 8.4-3.1 33.18 33.18 0 0 1 8.3-1.1c5.2 0 9.3 1.3 12.2 3.8s4.4 6.1 4.4 10.8v27h-7.8v-3.5a19.441 19.441 0 0 1-5.8 3.2 23.54 23.54 0 0 1-6.7 1Zm-7.3-12.6a5.646 5.646 0 0 0 2.6 4.8 11.193 11.193 0 0 0 6.6 1.8 16.256 16.256 0 0 0 5.9-1 14.449 14.449 0 0 0 4.9-2.9V47a19.778 19.778 0 0 0-4.8-1.8 24.933 24.933 0 0 0-5.7-.6 11.859 11.859 0 0 0-6.8 1.8 5.728 5.728 0 0 0-2.7 5ZM580.6 53.2v-24H572v-6.7h8.6V12.1l7.9-1.9v12.3h12v6.7h-12v22.1a5.94 5.94 0 0 0 1.4 4.4c.9.9 2.5 1.3 4.6 1.3a23.637 23.637 0 0 0 3-.2 10.857 10.857 0 0 0 2.8-.8v6.7a19.28 19.28 0 0 1-3.8.9 27.484 27.484 0 0 1-3.8.3c-3.9 0-7-.9-9-2.8-2-1.7-3.1-4.4-3.1-7.9Z"></path></g><path d="M127 90.2c12.5 0 30.6-2.6 30.6-17.5a12.678 12.678 0 0 0-.3-3.4L149.8 37c-1.7-7.1-3.2-10.3-15.7-16.6-9.7-5-30.8-13.1-37.1-13.1-5.8 0-7.5 7.5-14.4 7.5-6.7 0-11.6-5.6-17.9-5.6-6 0-9.9 4.1-12.9 12.5 0 0-8.4 23.7-9.5 27.2a4.216 4.216 0 0 0-.3 1.9c0 9.2 36.3 39.4 85 39.4Zm32.5-11.4c1.7 8.2 1.7 9.1 1.7 10.1 0 14-15.7 21.8-36.4 21.8-46.8 0-87.7-27.4-87.7-45.5a17.535 17.535 0 0 1 1.5-7.3C21.8 58.8 0 61.8 0 81c0 31.5 74.6 70.3 133.7 70.3 45.3 0 56.7-20.5 56.7-36.6-.1-12.8-11-27.3-30.9-35.9Z" fill="#e00"></path><path d="M159.5 78.8c1.7 8.2 1.7 9.1 1.7 10.1 0 14-15.7 21.8-36.4 21.8-46.8 0-87.7-27.4-87.7-45.5a17.535 17.535 0 0 1 1.5-7.3l3.7-9.1a4.877 4.877 0 0 0-.3 2c0 9.2 36.3 39.4 85 39.4 12.5 0 30.6-2.6 30.6-17.5a12.678 12.678 0 0 0-.3-3.4Z"></path><path d="M253.5 158.7a2.22 2.22 0 0 1-2.2-2.2V2.2a2.2 2.2 0 0 1 4.4 0v154.2a2.242 2.242 0 0 1-2.2 2.3Z" fill="#111"></path><text data-name="Demo Platform" transform="translate(1186 149)" fill="#111" font-size="82" font-family="'RedHatDisplay', 'Overpass', overpass, helvetica, arial, sans-serif" font-weight="700"><tspan x="-877.892" y="0">Demo Platform</tspan></text></svg></div></a>
</footer>
<script src="../_/js/vendor/clipboard.js"></script>
<script src="../_/js/site.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>
  </body>
</html>
