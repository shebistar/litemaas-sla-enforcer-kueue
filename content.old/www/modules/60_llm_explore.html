<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>What is a Large Language Model? :: Platform Foundation Bootcamp - RHOAI</title>
    <link rel="canonical" href="https://redhat-ai-services.github.io/rhoai-platform-foundation-bootcamp-instructions/modules/60_llm_explore.html">
    <meta name="generator" content="Antora 3.1.14">
<link rel="stylesheet" href="../_/css/site.css"><link rel="stylesheet" href="../_/css/site-extra.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<meta name="robots" content="all">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://demo.redhat.com/images/favicon.ico" type="image/x-icon">
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar"  style="background-color: #131313 !important;">
    <div class="navbar-brand">
      <div style="display: flex; flex-direction:row; padding: 12px 32px; gap: 16px;">
     </div>
      <div class="navbar-item site-title" style="color: #fff !important;flex: 1;">Platform Foundation Bootcamp - RHOAI</div>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="modules" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title" style="display: none;"><a href="index.html" class=" query-params-link">Navigation</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="01_welcome.html">Welcome and Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="05_environment_provisioning.html">Environment Provisioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">AI-Accelerator</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="20_ai-accelerator_review.html">Project Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="07_installation.html">Bootstrap Installation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="30_gitops_env_setup_dev_prod.html">Setup Dev &amp; Prod Environments</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">RHOAI Administration</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="32_dashboard_configuration.html">RHOAI Dashboard Configuration</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Notebooks</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="31_custom_notebook.html">Custom Notebook</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="09_remote_connect_notebook.html">Connect to Workbench Kernel</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Train, Store (S3), Deploy</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="33_model_training_car.html">Model Training</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="34_using_s3_storage.html">Using S3 Storage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="36_deploy_model.html">Deploy Model</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Data Science Pipelines</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="40_setup_pipeline_server.html">Setup Pipeline Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="41_introduction_to_kfp_pipelines.html">KFP Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="kfp_elyra_differences.html">Comparison between Elyra and KFP</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="build_custom_runtime_image.html">Custom Runtime Image</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="introduction_to_elyra_pipelines.html">Elyra Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="42_working_with_pipelines.html">Working with Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="43_custom_runtime_image.html">Advanced Pipeline Customization</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Distributed Training</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="50_distributed_training.html">Ray Cluster</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Large Language Model [LLM]</span>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="60_llm_explore.html">Explore LLMs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="70_rag_llm.html">RAG with LLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="composer_ai.html">Composer AI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Monitoring Data Science Models</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="80_trustyai_overview.html">TrustyAI Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="81_llm_evaluation.html">Evaluating Large Language Models</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Disconnected Environment</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="disconnected_install.html">RHOAI on Disconnected Environment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">GPU as a Service</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="90_environment_provisioning.html">Provisioning a GPU Environment with NVIDIA A10G Tensor Core GPU</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="91_gpu_as_a_service_intro.html">Introduction: GPU as a Service with GPU slicing and Kueue</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="92_nvidia_gpu_operator.html">Configuring NVIDIA GPU Time-Slicing on OpenShift</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="93_kueue_setup.html">Red Hat build of Kueue Operator Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="94_kueue_gpu_pricing_tier.html">Implementing GPU Pricing Tiers with Kueue</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="95_kueue_fair_sharing.html">Advanced GPU Quota Management and Preemption with Kueue</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Model-as-a-Service</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="100_maas_intro.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="101_maas_bootstrap.html">Environment Bootstrap</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="102_maas_as_developer.html">Using MaaS as Developer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="103_maas_as_platform_engineer.html">Configure a new model</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="104_maas_monitor.html">Monitor usage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Agentic AI with Llama Stack</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="97_agentic_ai_llama_stack_introduction.html">Introduction &amp; Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="98_agentic_ai_llama_stack_notebook_agents.html">Agentic AI Agents with Llama Stack Clients</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="99_agentic_ai_llama_stack_playground.html">Llama Stack Playground</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="#99_useful_tips.adoc">Useful Tips</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="#97_syncing_fork.adoc">Syncing Forked Project</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Navigation</span>
      <ul class="versions">
        <li class="version is-current">
          <a href="index.html">default</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="01_welcome.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li>Large Language Model [LLM]</li>
    <li><a href="60_llm_explore.html">Explore LLMs</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<article class="doc">
<h1 class="page">What is a Large Language Model?</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>A Large Language Model (LLM) is an instance of a foundation model. Foundation models are pre-trained on large amounts of unlabeled and self-supervised data. This means that the model learns from patterns in the data in a way that produces generalizable and adaptable output. LLMs are instances of foundation models applied specifically to text and text-like things (code).</p>
</div>
<div class="paragraph">
<p>Large language models are trained on large datasets of text, such as books, articles and conversations. These datasets can be extremely large. We&#8217;re talking petabytes of data. Training is the process of teaching the LLM to understand and generate language. It uses algorithms to learn patterns and predict what comes next. <sub><a href="https://www.ibm.com/topics/large-language-models">1</a></sub> Training an LLM with your data can help ensure that it can answer with the appropriate answer.</p>
</div>
<div class="paragraph">
<p>The term 'large' in LLM refers to the number of parameters in the model. These parameters are variables that the model uses to make predictions. The higher the number of parameters, the more detailed and nuanced the AI&#8217;s understanding of language can be. However, training such models requires considerable computational resources and specialized expertise. <sub><a href="https://www.run.ai/guides/machine-learning-engineering/llm-training">2</a></sub></p>
</div>
<div class="paragraph">
<p>There are many different types of LLMs for different use cases. Be sure to choose the appropriate one for you specific use case.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_explore_llms"><a class="anchor" href="#_explore_llms"></a>Explore LLMs</h2>
<div class="sectionbody">
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
As of Nov 22, 2024 the Node Feature Discovery and NVIDIA Operator appear to be broken on the latest version of OpenShift (4.17), be sure to use 4.16 when building a cluster so that the taints and tolerations work correctly. This may be fixed by Red Hat Engineering soon, so this warning can be removed when the operators are compatible with latest OCP.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the <a href="https://github.com/redhat-ai-services/ai-accelerator">ai-accelerator project</a>, there is an example of an LLM. Let&#8217;s look at the <a href="https://github.com/redhat-ai-services/ai-accelerator/tree/main/tenants/ai-example/single-model-serving-tgis">single-model-serving-tgis</a> example.</p>
</div>
<div class="paragraph">
<p>This inference service uses <a href="https://huggingface.co/google/flan-t5-small">flan-t5-small</a> model.</p>
</div>
<div class="paragraph">
<p>The FLAN-T5 is a Large Language Model open sourced by Google under the Apache license at the end of 2022. We are using the small size which is 80 million parameters. FLAN-T5 models use the following models and techniques: the pretrained model T5 (Text-to-Text Transfer Transformer) and the FLAN (Finetuning Language Models) collection to do fine-tuning multiple tasks.</p>
</div>
<div class="paragraph">
<p>The model has been uploaded to minio S3 automatically when we ran the bootstrap script. The inference service uses the <em>TGIS Standalone ServingRuntime for KServe</em> and is <em><strong>not</strong></em> using a GPU.</p>
</div>
<div class="paragraph">
<p>Take a look at the InferenceService and the ServingRuntime resource in your <em><strong>GPU</strong></em> cluster.</p>
</div>
<div class="paragraph">
<p>Now let&#8217;s take a look at the <a href="https://github.com/redhat-ai-services/ai-accelerator/tree/main/tenants/ai-example/single-model-serving-vllm">single-model-serving-vllm</a> example. This inference service uses IBM&#8217;s <a href="https://huggingface.co/ibm-granite/granite-3b-code-base">granite-3b-code-base</a> model.</p>
</div>
<div class="paragraph">
<p>The Granite-3B-Code-Base-2K is a decoder-only code model designed for code generative tasks (e.g., code generation, code explanation, code fixing, etc.). It is trained from scratch with a two-phase training strategy. In phase 1, our model is trained on 4 trillion tokens sourced from 116 programming languages, ensuring a comprehensive understanding of programming languages and syntax. In phase 2, our model is trained on 500 billion tokens with a carefully designed mixture of high-quality data from code and natural language domains to improve the modelsâ€™ ability to reason and follow instructions. Prominent enterprise use cases of LLMs in software engineering productivity include code generation, code explanation, code fixing, generating unit tests, generating documentation, addressing technical debt issues, vulnerability detection, code translation, and more. All Granite Code Base models, including the 3B parameter model, are able to handle these tasks as they were trained on a large amount of code data from 116 programming languages.</p>
</div>
<div class="paragraph">
<p>The Inference Service uses a vllm ServingRuntime which can be found <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/serving-runtimes/vllm_runtime/vllm-runtime.yaml">here</a>.</p>
</div>
<div class="sect2">
<h3 id="_nodes_and_taints"><a class="anchor" href="#_nodes_and_taints"></a>Nodes and Taints</h3>
<div class="paragraph">
<p>Notice in the InferenceService of the vllm example there are GPU sections:</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/vllm_gpu.png" alt="vllm gpu">
</div>
</div>
<div class="paragraph">
<p>As you can see in the resources section, this Inference Service is needing a gpu to function properly.</p>
</div>
<div class="paragraph">
<p>You can also see that there is a <code>toleration</code> policy. When using the toleration on this resource, it is telling the cluster to deploy on a node that has a GPU attached to it so it can use it. It does this by using the toleration and a taint.</p>
</div>
<div class="paragraph">
<p>In this case, a node with a taint is a node with a GPU attached to it. The toleration has a key to validate against the taint. If it matches, the pod can run on the node.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s take a look at the node:</p>
</div>
<div class="paragraph">
<p>In <code>OpenShift Dashboard &gt; Compute &gt; Nodes</code> we can see we have 3 nodes. Let&#8217;s look at the one with the gpu.</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/nodes.png" alt="nodes">
</div>
</div>
<div class="paragraph">
<p>Select the GPU node. The instance is g5.2xlarge which has a gpu. You can see the different type of instances here: <a href="https://aws.amazon.com/ec2/instance-types/" class="bare">https://aws.amazon.com/ec2/instance-types/</a></p>
</div>
<div class="paragraph">
<p>If we look at the node details and scroll down we can see the taint that is has.</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/node_taint_edit.png" alt="node taint edit">
</div>
</div>
<div class="paragraph">
<p>We can also see it in the yaml.</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/node_taint.png" alt="node taint">
</div>
</div>
<div class="paragraph">
<p>In the node yaml we can view the labels associated with the node. Lets look at the the <code>nvidia.com/*</code> labels. As you can see we have: <code>nvidia.com/gpu.count: '1'</code> which tells us that we have a gpu attached to this node</p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/node_gpu_count.png" alt="node gpu count">
</div>
</div>
<div class="paragraph">
<p>We can also run a <code>oc describe`</code> on the node:</p>
</div>
<div class="paragraph">
<p><code>oc describe node ip-<strong>-<strong>-</strong>-</strong>**.us-east-2.compute.internal | grep gpu</code></p>
</div>
<div class="imageblock bordershadow">
<div class="content">
<img src="_images/node_describe_gpu.png" alt="node describe gpu">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_test_model_notebooks"><a class="anchor" href="#_test_model_notebooks"></a>Test Model Notebooks</h3>
<div class="paragraph">
<p>After exploring the GPU Node details, open RHOAI and launch new workbench and run the tests for the LLMs. These can be found in the <code><a href="https://github.com/redhat-ai-services/ai-accelerator" class="bare">https://github.com/redhat-ai-services/ai-accelerator</a></code></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Fraud detection model - tenants/ai-example/multi-model-serving/test</p>
</li>
<li>
<p>FLAN-T5 small model -  tenants/ai-example/single-model-serving-tgis/test</p>
</li>
<li>
<p>Granite model - tenants/ai-example/single-model-serving-vllm/test</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These are very simple tests to make sure that the InferenceService is working. View the logs of the inference service pod while you test.</p>
</div>
<div class="sect3">
<h4 id="_testing_fraud_detection_model"><a class="anchor" href="#_testing_fraud_detection_model"></a>Testing Fraud Detection Model</h4>
<div class="paragraph">
<p>Testing this model includes the following steps:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Create workbench in ai-example-multi-model-serving Data Science Project using Standard Data Science Python v3.11 notebook image</p>
</li>
<li>
<p>Clone your fork of ai-example repository in Jupiter Notebook in created workbench</p>
</li>
<li>
<p>Open tenants/ai-example/multi-model-serving/test/test-using-grpc.ipynb Jupiter Notebook and run through cells.</p>
</li>
<li>
<p>Change values in the data field in the fifth cell to observe how prediction result change.</p>
</li>
<li>
<p>Open tenants/ai-example/multi-model-serving/test/test-using-rest.ipynb Jupiter Notebook. In the first cell make sure to replace apps base URL in infer_url field with apps base URL of your gpu cluster. Run through notebook cells and observe results.</p>
</li>
<li>
<p>Change values in the data field in the third cell to observe how prediction result change.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_testing_flan_t5_small_model"><a class="anchor" href="#_testing_flan_t5_small_model"></a>Testing FLAN-T5 small model</h4>
<div class="paragraph">
<p>Testing this model includes the following steps:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Create workbench in ai-example-single-model-serving Data Science Project using Standard Data Science Python v3.11 notebook image</p>
</li>
<li>
<p>Clone your fork of ai-example repository in Jupiter Notebook in created workbench</p>
</li>
<li>
<p>Open tenants/ai-example/single-model-serving-tgis/test/test-using-grpc.iypnb Jupiter Notebook. In the first cell make sure to replace apps base URL in infer_endpoint field with apps base URL of your gpu cluster. Run through notebook cells and observe results.</p>
</li>
<li>
<p>As recommended in notebook comments try changing question in the third cell and observe answers. Explain why answers are often not correct.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_testing_granite_model"><a class="anchor" href="#_testing_granite_model"></a>Testing Granite model</h4>
<div class="paragraph">
<p>Testing this model includes the following steps:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Reuse the workbench from the previous test</p>
</li>
<li>
<p>Open tenants/ai-example/single-model-serving-vllm/test/granite-test.ipynb Jupiter Notebook. In the first cell make sure to replace apps base URL in infer_endpoint field with apps base URL of your gpu cluster. Run through notebook cells and observe results.</p>
</li>
<li>
<p>Note that answers provided by this model will be unintelligible. This is a known issue and being investigated.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_references"><a class="anchor" href="#_references"></a>References</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://www.ibm.com/topics/large-language-models" class="bare">https://www.ibm.com/topics/large-language-models</a></p>
</li>
<li>
<p><a href="https://www.run.ai/guides/machine-learning-engineering/llm-training" class="bare">https://www.run.ai/guides/machine-learning-engineering/llm-training</a></p>
</li>
<li>
<p><a href="https://bbycroft.net/llm">LLM Visualization</a> - A peek "under the hood" showing what&#8217;s inside some common LLMs</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <a href="https://demo.redhat.com" target="_blank" class="poweredBy"><p>Powered by</p><div class="labInfo_poweredBy" style="display: block; width: 260px;"><svg class="labInfo_poweredByLogo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1508.5 178.739"><g fill="#111"><path d="M316.6 63.2v-56H342a21.279 21.279 0 0 1 7.8 1.3 18.111 18.111 0 0 1 5.9 3.5 15.577 15.577 0 0 1 5 11.8 15.051 15.051 0 0 1-3.1 9.5 16.836 16.836 0 0 1-8.4 5.8l12.5 24.1h-9.3l-11.6-23H325v23Zm24.7-48.6H325v18.7h16.3q5.25 0 8.1-2.7a8.7 8.7 0 0 0 2.8-6.6 8.7 8.7 0 0 0-2.8-6.6c-1.8-1.9-4.5-2.8-8.1-2.8ZM364.1 42.8a20.674 20.674 0 0 1 1.6-8.2 20.288 20.288 0 0 1 4.3-6.7 19.92 19.92 0 0 1 6.5-4.5 19.718 19.718 0 0 1 8-1.6 18.463 18.463 0 0 1 7.8 1.6 18.677 18.677 0 0 1 6.2 4.5 20.927 20.927 0 0 1 4.1 6.8 23.2 23.2 0 0 1 1.5 8.4v2.3H372a13.822 13.822 0 0 0 4.6 8.4 13.6 13.6 0 0 0 9.1 3.3 15.553 15.553 0 0 0 5.7-1 12.858 12.858 0 0 0 4.6-2.6l5.1 5a25.983 25.983 0 0 1-7.4 4.1 24.69 24.69 0 0 1-8.4 1.3 21.306 21.306 0 0 1-8.4-1.6 22.763 22.763 0 0 1-6.8-4.4 20.788 20.788 0 0 1-4.5-6.7 23.2 23.2 0 0 1-1.5-8.4Zm20.2-14.2a11.527 11.527 0 0 0-8 3 13.046 13.046 0 0 0-4.2 7.8h24.2a13.091 13.091 0 0 0-4.2-7.8 11.106 11.106 0 0 0-7.8-3ZM443.1 63.2v-3.8a19.448 19.448 0 0 1-5.8 3.3 18.924 18.924 0 0 1-6.7 1.2 19.824 19.824 0 0 1-14.6-6.1 22.268 22.268 0 0 1-4.4-6.7 21.812 21.812 0 0 1 0-16.4A20.534 20.534 0 0 1 416 28a19.335 19.335 0 0 1 6.6-4.5 20.334 20.334 0 0 1 8.2-1.6 20.7 20.7 0 0 1 6.6 1 19.415 19.415 0 0 1 5.7 3V7.2l8-1.8v57.8Zm-25.2-20.4a13.718 13.718 0 0 0 4 10.1 13.45 13.45 0 0 0 9.8 4.1 14.956 14.956 0 0 0 6.4-1.3 15.954 15.954 0 0 0 4.9-3.6V33.6a14.988 14.988 0 0 0-4.9-3.5 15.271 15.271 0 0 0-6.4-1.3 13.423 13.423 0 0 0-9.9 4 13.806 13.806 0 0 0-3.9 10ZM478.1 63.2v-56h8.4v24h29.8v-24h8.4v56h-8.4V38.8h-29.8v24.4ZM547.2 64a16.483 16.483 0 0 1-10.8-3.5 11.037 11.037 0 0 1-4.2-8.9 10.375 10.375 0 0 1 4.7-9.2 20.76 20.76 0 0 1 11.8-3.2 27.841 27.841 0 0 1 5.8.6 27.374 27.374 0 0 1 5.3 1.6v-4.3a8.143 8.143 0 0 0-2.6-6.5 11.452 11.452 0 0 0-7.4-2.2 20.788 20.788 0 0 0-6 .9 34.616 34.616 0 0 0-6.6 2.6l-3-6a54.169 54.169 0 0 1 8.4-3.1 33.18 33.18 0 0 1 8.3-1.1c5.2 0 9.3 1.3 12.2 3.8s4.4 6.1 4.4 10.8v27h-7.8v-3.5a19.441 19.441 0 0 1-5.8 3.2 23.54 23.54 0 0 1-6.7 1Zm-7.3-12.6a5.646 5.646 0 0 0 2.6 4.8 11.193 11.193 0 0 0 6.6 1.8 16.256 16.256 0 0 0 5.9-1 14.449 14.449 0 0 0 4.9-2.9V47a19.778 19.778 0 0 0-4.8-1.8 24.933 24.933 0 0 0-5.7-.6 11.859 11.859 0 0 0-6.8 1.8 5.728 5.728 0 0 0-2.7 5ZM580.6 53.2v-24H572v-6.7h8.6V12.1l7.9-1.9v12.3h12v6.7h-12v22.1a5.94 5.94 0 0 0 1.4 4.4c.9.9 2.5 1.3 4.6 1.3a23.637 23.637 0 0 0 3-.2 10.857 10.857 0 0 0 2.8-.8v6.7a19.28 19.28 0 0 1-3.8.9 27.484 27.484 0 0 1-3.8.3c-3.9 0-7-.9-9-2.8-2-1.7-3.1-4.4-3.1-7.9Z"></path></g><path d="M127 90.2c12.5 0 30.6-2.6 30.6-17.5a12.678 12.678 0 0 0-.3-3.4L149.8 37c-1.7-7.1-3.2-10.3-15.7-16.6-9.7-5-30.8-13.1-37.1-13.1-5.8 0-7.5 7.5-14.4 7.5-6.7 0-11.6-5.6-17.9-5.6-6 0-9.9 4.1-12.9 12.5 0 0-8.4 23.7-9.5 27.2a4.216 4.216 0 0 0-.3 1.9c0 9.2 36.3 39.4 85 39.4Zm32.5-11.4c1.7 8.2 1.7 9.1 1.7 10.1 0 14-15.7 21.8-36.4 21.8-46.8 0-87.7-27.4-87.7-45.5a17.535 17.535 0 0 1 1.5-7.3C21.8 58.8 0 61.8 0 81c0 31.5 74.6 70.3 133.7 70.3 45.3 0 56.7-20.5 56.7-36.6-.1-12.8-11-27.3-30.9-35.9Z" fill="#e00"></path><path d="M159.5 78.8c1.7 8.2 1.7 9.1 1.7 10.1 0 14-15.7 21.8-36.4 21.8-46.8 0-87.7-27.4-87.7-45.5a17.535 17.535 0 0 1 1.5-7.3l3.7-9.1a4.877 4.877 0 0 0-.3 2c0 9.2 36.3 39.4 85 39.4 12.5 0 30.6-2.6 30.6-17.5a12.678 12.678 0 0 0-.3-3.4Z"></path><path d="M253.5 158.7a2.22 2.22 0 0 1-2.2-2.2V2.2a2.2 2.2 0 0 1 4.4 0v154.2a2.242 2.242 0 0 1-2.2 2.3Z" fill="#111"></path><text data-name="Demo Platform" transform="translate(1186 149)" fill="#111" font-size="82" font-family="'RedHatDisplay', 'Overpass', overpass, helvetica, arial, sans-serif" font-weight="700"><tspan x="-877.892" y="0">Demo Platform</tspan></text></svg></div></a>
</footer>
<script src="../_/js/vendor/clipboard.js"></script>
<script src="../_/js/site.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>
  </body>
</html>
