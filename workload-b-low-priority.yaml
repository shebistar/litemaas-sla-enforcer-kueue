# --- WORKLOAD A: High-Priority (Reserved Tier) ---
# This RayCluster represents a mission-critical job from a "Reserved" MaaS customer (team-a).
# It has a high priority and requests a guaranteed GPU resource.
# Its request for shared CPU/memory will trigger the preemption of the lower-priority workload.
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: raycluster-prod
  namespace: team-a
  labels:
    # This label directs the workload to the LocalQueue in the team-a namespace.
    kueue.x-k8s.io/queue-name: lq-team-a
spec:
  rayVersion: '2.9.0'
  headGroupSpec:
    rayStartParams: {}
    template:
      spec:
        # This high-priority class ensures it can preempt other workloads.
        priorityClassName: prod-priority
        containers:
          - name: ray-head
            image: rayproject/ray:2.9.0
            resources:
              requests:
                cpu: "1"
                memory: "2Gi"
              limits:
                cpu: "1"
                memory: "2Gi"
            ports:
              - containerPort: 6379
                name: gcs-server
              - containerPort: 8265
                name: dashboard
              - containerPort: 10001
                name: client
  workerGroupSpecs:
  - replicas: 1
    minReplicas: 1
    maxReplicas: 1
    groupName: gpu-group
    rayStartParams: {}
    template:
      spec:
        priorityClassName: prod-priority
        # Toleration to allow scheduling on the tainted GPU worker nodes.
        tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
        containers:
        - name: ray-worker
          image: rayproject/ray:2.9.0
          resources:
            requests:
              # This workload requests both shared CPU and a guaranteed GPU.
              cpu: "1"
              memory: "2Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "1"
              memory: "2Gi"
              nvidia.com/gpu: "1"

